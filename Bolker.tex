\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\title{Comparison of methods}
\author{}
\date{}
 
\begin{document}

\maketitle

\section{compare}

\subsection{"Xr" Method: \(y \sim X_r\)}

In this method, we extract the random effect representation \(X_r\) of the smooth term and use it as a fixed effect in our model. Essentially, we are fitting the model:

\begin{equation}
y = X_r \beta + \epsilon
\end{equation}

Here, \(X_r\) is the design matrix for the smooth term, \(\beta\) is the vector of coefficients, and \(\epsilon\) is the error term.

\subsection{Ben Bolker's Method: \(y \sim (X_r | \text{dummy})\)}

Ben Bolker's approach integrates smooth terms directly into the \texttt{glmmTMB} package. The smooth term is represented in both the fixed and random effects part of the model. The model can be represented as:

\[
y = X_f \beta_f + Z \beta_r + \epsilon
\]

Here, \(y\) is the \(n \times 1\) response vector, \(X_f\) is the \(n \times q\) design matrix for the fixed effects, \(Z\) is the \(n \times m\) design matrix for the random effects (which includes the smooth terms), \(\beta_f\) is the \(q \times 1\) vector of fixed effect coefficients, \(\beta_r\) is the \(m \times 1\) vector of random effect coefficients, and \(\epsilon\) is the \(n \times 1\) error term.

The likelihood function is augmented with a penalty term \(P\):

\[
L(y | \beta_f, \beta_r) \propto e^{-\frac{1}{2} \beta_r^T S \beta_r}
\]

Here, \(S\) is the penalty matrix, which is used to smooth the curve.

we have a penalty matrix \(S\) and a basis function matrix \(B\). The smooth term can be represented as:

\[
s(x) = B \alpha
\]

Where \( \alpha \) is the vector of smooth coefficients. The penalty term for the smooth is:

\[
P = \alpha^T S \alpha
\]



e.g cubic splines, the penalty matrix \( S \) is typically a diagonal matrix with the first few diagonal elements set to zero. These zero elements correspond to the basis functions that make up the polynomial part of the spline (usually the intercept and the linear term). The remaining diagonal elements are positive and impose a penalty on the curvature of the spline.


\[
S = \begin{pmatrix}
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & \lambda_1 & 0 \\
0 & 0 & 0 & \lambda_2
\end{pmatrix}
\]

Here, \( \lambda_1 \) and \( \lambda_2 \) are positive penalty terms.

In Bolker's method, the first two rows and columns from \( S \) are moved to the fixed effect model matrix \( X_f \). Because these rows and columns are zeros, moving them doesn't change the penalty imposed by \( S \). Instead, it changes how these terms are estimated:

- In the \( y \sim X_r \) method, these terms are estimated as fixed effects without any penalty.
- In the \( y \sim (X_r | \text{dummy}) \) method, these terms are estimated as fixed effects but are also subject to the penalty imposed by the random effects structure.
\newline

 Let's assume \(S_1\) represents these first two rows and columns, and \(S_2\) represents the remaining part of \(S\).

\[
S = \begin{pmatrix}
S_1 & 0 \\
0 & S_2
\end{pmatrix}
\]

The corresponding basis function matrix \(B\) can also be partitioned as \(B = [B_1, B_2]\), where \(B_1\) corresponds to \(S_1\) and \(B_2\) corresponds to \(S_2\).

The smooth term \(s(x)\) can then be partitioned as:

\[
s(x) = B_1 \alpha_1 + B_2 \alpha_2
\]

Here, \(\alpha_1\) would be treated as fixed effects and \(\alpha_2\) as random effects.


The GLMM is updated to:

\[
y = X_f \beta_f + B_1 \alpha_1 + Z \beta_r + B_2 \alpha_2 + \epsilon
\]

Here, \(B_1 \alpha_1\) is part of \(X_f\) and is estimated as fixed effects (\(\beta_f\)), while \(B_2 \alpha_2\) is part of \(Z\) and is estimated as random effects (\(\beta_r\)).


\subsection{Key Differences}

\begin{enumerate}
    \item \textbf{Intercept and Fixed Effects}: In Bolker's method, the first two rows and columns from the penalty matrix \(S\) are moved to the fixed effect model matrix. This essentially acts as an intercept. These terms are part of \(X_f\) and are estimated as fixed effects \(\beta_f\).
    
    \item \textbf{Random Effects}: The remaining part of the smooth term is included in the random effects matrix \(Z\), and its effects are estimated as random effects \(\gamma\).
    
    \item \textbf{Penalty Matrix}: The penalty matrix \(S\) is used to enforce smoothness, and its coefficients \(\theta\) are estimated in the model.
\end{enumerate}


\section{Penalization in Smooth Terms}

\subsection{Xr Method:}

In this approach, we are directly using the \(X_r\) terms as fixed effects without any explicit penalization. The \(X_r\) terms are essentially the basis functions that represent the smooth term. When you include them as fixed effects, they are not penalized, meaning that the model does not enforce any smoothness constraints on these terms. The model will fit these terms as it would any other fixed effect, aiming to minimize the residual sum of squares without any regularization.

Mathematically, the objective function looks something like:

\begin{equation}
\text{minimize} \quad ||y - X_r \beta||^2
\end{equation}

\subsection{Ben Bolker's Method:}

In Bolker's method, the smooth terms are included as both fixed and random effects, and they are subject to penalization through the penalty matrix \(S\). The penalty matrix \(S\) is used to enforce smoothness in the estimated function. The objective function in this case would include a penalty term:

\begin{equation}
\text{minimize} \quad ||y - X_f \beta_f - Z \gamma - S \theta||^2 + \lambda \theta^T S \theta
\end{equation}

Here, \(\lambda\) is the smoothing parameter, and \(S\) is the penalty matrix. The term \(\theta^T S \theta\) is the penalty term that enforces smoothness. The model aims to minimize this objective function, balancing the fit to the data and the smoothness of the estimated function.

\subsection{Key Differences in Penalization}

\begin{enumerate}
    \item \textbf{Explicit vs. Implicit Penalization}: Xr method does not include any explicit penalization, while Bolker's method includes a penalty term to enforce smoothness.
    
    \item \textbf{Objective Function}: The objective function in the Xr method aims to minimize the residual sum of squares, while Bolker's method aims to minimize a penalized residual sum of squares.
    
    \item \textbf{Smoothing Parameter}: In Ben Bolker's method, the smoothing parameter \(\lambda\) controls the trade-off between fit and smoothness, which is not present in the Xr method.
\end{enumerate}

\section{Summary}

In summary, the \(X_r\) terms in Xr method are essentially unpenalized, while in Bolker's method, the smooth terms are subject to penalization to enforce smoothness.












\section{Discussion}

does

\subsection{Challenges and Upsides}

\textbf{Challenges:}
\begin{itemize}
    \item Complexity in constructing \(X_r\) terms.
    \item Potential for overfitting.
\end{itemize}

\textbf{Upsides:}
\begin{itemize}
    \item Greater flexibility compared to standard GLMMs and GAMMs.
    \item Ability to capture complex relationships in the data.
\end{itemize}


Models using \(X_r\) terms as basis function terms offer a viable and flexible approach for complex data analysis. However, they come with their own set of challenges that need to be carefully considered.


\subsubsection{smooth2random Function}
The \texttt{smooth2random} function from the \texttt{mgcv} package is used to convert a smooth object into a random effect representation. This conversion facilitates the ability to implement a smooth in the \texttt{glmmTMB} model by transforming the smooth term into a structure that can be handled as a random effect.

\begin{verbatim}
re <- mgcv::smooth2random(sm, "", type=2)
\end{verbatim}

Here, the function takes the smooth object \texttt{sm} and converts it into a random effect representation, stored in the \texttt{re} object. Here is a short summary of what this function does.

\begin{itemize}
    \item \textbf{Check for Fixed Smooth:} If the smooth term is fixed (not estimated from the data), the function returns it as a fixed effect.
    \item \textbf{Eigen Decomposition:} The function performs an eigen decomposition on the penalty matrix of the smooth term to obtain the eigenvalues and eigenvectors.
    \item \textbf{Transformation:} The eigenvectors and eigenvalues are used to transform the basis functions of the smooth term into a parameterization suitable for random effects.
    \item \textbf{Handling Multiple Random Effects:} If the smooth term contains multiple random effects, the function handles them accordingly, creating separate matrices for each.
    \item \textbf{Return Random Effects:} The function returns the random effects and other components as a list, ready to be used in a mixed model.
\end{itemize}


\subsubsection{Prediction Function and Matrix Creation}
A custom function \texttt{s2rPred} (Devin Johnson) is defined to create a prediction matrix using the smooth term and random effect representation. The function transforms the smooth term into a random effect parameterization, reorders columns, and constructs a return object containing random effect matrices.

\subsubsection{Model Fitting and Comparison}
The code fits both a GLMM using \texttt{glmmTMB} and a GAM using \texttt{mgcv}, and then compares various aspects of the two models, including sigma, intercept, fitted values, random effects, and log-likelihood.

\subsubsection{Conclusion}
The combination of \texttt{smoothCon} and \texttt{smooth2random} functions allows for a flexible modeling of the relationship between the response and predictor variables in the \texttt{glmmTMB} model. By converting the smooth term into a random effect representation, the code demonstrates how to incorporate both fixed and random effects into a spline regression model, providing a powerful tool for statistical modeling.

\subsection{Comparing results}

The \textbf{tmb\_model} has an AIC of 5612 and a BIC of 5649. We were not able to extract the AIC or BIC from the \textbf{gamm\_model}, but its summary output from \texttt{gamm\_model\$gam} suggests that it is quite comparable to the \textbf{gtmb0} model. The AIC and BIC for the \textbf{gtmb0} model are 5307 and 5463, respectively, which indicates an improvement over the standard \textbf{tmb\_model}.

\newpage














\end{document}
